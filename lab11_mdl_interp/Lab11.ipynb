{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science\n",
    "\n",
    "## Lab 11 Interpreting Machine Learning Models \n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2021**<br/>\n",
    "**Instructors**: Pavlos Protopapas and Natesh Pillai\\\n",
    "**Lab Team**: Marios Mattheakis, Hayden Joy, Chris Gumb, and Eleni Kaxiras<br/>\n",
    "**Authors**: Kevin Rader, Pavlos Protopapas, Yongwhan Lim, and Chris Gumb\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Table of Contents \n",
    "- Feature Importance \n",
    "- Permutation Importance\n",
    "- ELI5\n",
    "- Interpretation Through Predictions\n",
    "- Surrogate Explainer Model\n",
    "- LIME \n",
    "- SHAP\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "- Interpret the results of 'black box' machine learning models using several methods. \n",
    "- Explore the ELI5, LIME, and SHAP packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.20.0 in /Users/wruths/opt/anaconda3/envs/cs109a/lib/python3.9/site-packages (1.20.0)\n",
      "Requirement already satisfied: numba==0.54.0 in /Users/wruths/opt/anaconda3/envs/cs109a/lib/python3.9/site-packages (0.54.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/wruths/opt/anaconda3/envs/cs109a/lib/python3.9/site-packages (from numba==0.54.0) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /Users/wruths/opt/anaconda3/envs/cs109a/lib/python3.9/site-packages (from numba==0.54.0) (57.4.0)\n"
     ]
    }
   ],
   "source": [
    "# required for SHAP and needs to be run before imports\n",
    "!pip install numpy==1.20.0 numba==0.54.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7w/dkjvv8f57hv2qg30psq105jr0000gn/T/ipykernel_24817/309781706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m109\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Here are the decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "\n",
    "np.random.seed(109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of time, we'll fit some models quickly and they won't converge\n",
    "# We'll supress those pesky warnings\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Interpretability ðŸ”Ž\n",
    "\n",
    "- As a data scientist, you need to know ins and outs of machine learning models.\n",
    "- Often you need to provide a **trustworthy, transparent, and accountable explanation** to stakeholders beyond the final evaluation metrics (e.g., Accuracy, ROC-AUC score, etc.).\n",
    "- To provide a good justification, we would do well to have an easily generalizable framework to explain a machine learning model.\n",
    "\n",
    "But there are inherent trade-off between model interpretability and accuracy.\\\n",
    "And there are many ways to explain the machine learning models:\n",
    "- Use only interpretable models\n",
    "    - Linear regression, logistic regression, decision trees, etc.\n",
    "    - But these are often times too simple and don't perform well!\n",
    "- Use model specific interpretation methods\n",
    "    - Lacks generalization because it is model dependent!\n",
    "- Use **model-agnostic methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will be using the `Heart.csv` data set we've seen many times before.  We to predict `AHD` from the other features and then interpret the models predictions.\\\n",
    "For this reason it will be nice to have a description of all the features at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data includes:\n",
    "- Age: displays the age of the individual.\n",
    "- Sex: displays the sex of the individual using the following format :\n",
    "    - 1 = male\n",
    "    - 0 = female\n",
    "- Chest-pain type: displays the type of chest-pain experienced by the individual using the following format :\n",
    "    - typical angina\n",
    "    - atypical angina\n",
    "    - nonâ€”anginal pain\n",
    "    - asymptotic\n",
    "- Resting Blood Pressure: displays the resting blood pressure value of an individual in mmHg (unit)\n",
    "- Serum Cholestrol: displays the serum cholesterol in mg/dl (unit)\n",
    "- Fasting Blood Sugar: compares the fasting blood sugar value of an individual with 120mg/dl.\n",
    "    - If fasting blood sugar > 120mg/dl then : 1 (true)\n",
    "    - else : 0 (false)\n",
    "- Resting ECG : displays resting electrocardiographic results\n",
    "    - 0 = normal\n",
    "    - 1 = having ST-T wave abnormality\n",
    "    - 2 = left ventricular hyperthrophy\n",
    "- Max heart rate achieved : displays the max heart rate achieved by an individual.\n",
    "- Exercise induced angina :\n",
    "    - 1 = yes\n",
    "    - 0 = no\n",
    "- ST depression induced by exercise relative to rest (`Oldspeak`)\n",
    "- Peak exercise ST segment (`Slope`):\n",
    "    - 1 = upsloping\n",
    "    - 2 = flat\n",
    "    - 3 = downsloping\n",
    "- Number of major vessels (0â€“3) colored by flourosopy (`Ca`)\n",
    "- Thal : displays the thalassemia :\n",
    "    - normal\n",
    "    - fixed defect\n",
    "    - reversible defect\n",
    "- Diagnosis of heart disease : Displays whether the individual is suffering from heart disease or not :\n",
    "    - Yes\n",
    "    - No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in the data and do a bit of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df = pd.read_csv('data/Heart.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
       "1   63    1       typical     145   233    1        2    150      0      2.3   \n",
       "2   67    1  asymptomatic     160   286    0        2    108      1      1.5   \n",
       "3   67    1  asymptomatic     120   229    0        2    129      1      2.6   \n",
       "4   37    1    nonanginal     130   250    0        0    187      0      3.5   \n",
       "5   41    0    nontypical     130   204    0        2    172      0      1.4   \n",
       "\n",
       "   Slope   Ca        Thal  AHD  \n",
       "1      3  0.0       fixed   No  \n",
       "2      2  3.0      normal  Yes  \n",
       "3      2  2.0  reversable  Yes  \n",
       "4      3  0.0      normal   No  \n",
       "5      1  0.0      normal   No  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(heart_df.shape)\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.672241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.937438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         Sex      RestBP        Chol         Fbs     RestECG  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868  131.689769  246.693069    0.148515    0.990099   \n",
       "std      9.038662    0.467299   17.599748   51.776918    0.356198    0.994971   \n",
       "min     29.000000    0.000000   94.000000  126.000000    0.000000    0.000000   \n",
       "25%     48.000000    0.000000  120.000000  211.000000    0.000000    0.000000   \n",
       "50%     56.000000    1.000000  130.000000  241.000000    0.000000    1.000000   \n",
       "75%     61.000000    1.000000  140.000000  275.000000    0.000000    2.000000   \n",
       "max     77.000000    1.000000  200.000000  564.000000    1.000000    2.000000   \n",
       "\n",
       "            MaxHR       ExAng     Oldpeak       Slope          Ca  \n",
       "count  303.000000  303.000000  303.000000  303.000000  299.000000  \n",
       "mean   149.607261    0.326733    1.039604    1.600660    0.672241  \n",
       "std     22.875003    0.469794    1.161075    0.616226    0.937438  \n",
       "min     71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%    133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%    153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%    166.000000    1.000000    1.600000    2.000000    1.000000  \n",
       "max    202.000000    1.000000    6.200000    3.000000    3.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_df[['Age','Sex','ChestPain','RestBP','Chol','Fbs','RestECG','MaxHR','ExAng','Oldpeak','Slope','Ca','Thal']]\n",
    "y = (heart_df['AHD']=='Yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are our categorical columns\n",
    "X = X.assign(ChestPain=X['ChestPain'].astype('category').cat.codes)\n",
    "X = X.assign(Thal=X['Thal'].astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode of Ca is 0\n",
    "X['Ca']=X['Ca'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're actually getting indices from the split call!\n",
    "itrain, itest = train_test_split(range(X.shape[0]), train_size=0.80, stratify=heart_df.AHD)\n",
    "\n",
    "X_train = X.iloc[itrain, :]\n",
    "X_test = X.iloc[itest, :]\n",
    "y_train = y.iloc[itrain]\n",
    "y_test = y.iloc[itest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
       "1     63    1          3     145   233    1        2    150      0      2.3   \n",
       "2     67    1          0     160   286    0        2    108      1      1.5   \n",
       "3     67    1          0     120   229    0        2    129      1      2.6   \n",
       "4     37    1          1     130   250    0        0    187      0      3.5   \n",
       "5     41    0          2     130   204    0        2    172      0      1.4   \n",
       "..   ...  ...        ...     ...   ...  ...      ...    ...    ...      ...   \n",
       "299   45    1          3     110   264    0        0    132      0      1.2   \n",
       "300   68    1          0     144   193    1        0    141      0      3.4   \n",
       "301   57    1          0     130   131    0        0    115      1      1.2   \n",
       "302   57    0          2     130   236    0        2    174      0      0.0   \n",
       "303   38    1          1     138   175    0        0    173      0      0.0   \n",
       "\n",
       "     Slope   Ca  Thal  \n",
       "1        3  0.0     0  \n",
       "2        2  3.0     1  \n",
       "3        2  2.0     2  \n",
       "4        3  0.0     1  \n",
       "5        1  0.0     1  \n",
       "..     ...  ...   ...  \n",
       "299      2  0.0     2  \n",
       "300      2  2.0     2  \n",
       "301      2  1.0     2  \n",
       "302      2  1.0     1  \n",
       "303      1  0.0     1  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After preprocessing\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** ðŸ¤” How were the categorical variables handled?  How were missing values treated?  Were these wise choices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Four Untuned ML Models\n",
    "\n",
    "Start with 2 decision tree models and evaluate using AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a possibly underfit (depth = 3) decision tree classifier\n",
    "dt3 = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "dt3.fit(X_train,y_train)\n",
    "\n",
    "# fit an overfit (depth = 10) decision tree classifier\n",
    "dt10 = tree.DecisionTreeClassifier(max_depth = 10)\n",
    "dt10.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on train for dt3: 0.894230107970566\n",
      "AUC on test for dt3: 0.8398268398268398\n",
      "AUC on train for dt10: 1.0\n",
      "AUC on test for dt10: 0.6520562770562771\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using AUC\n",
    "print(\"AUC on train for dt3:\",sk.metrics.roc_auc_score(y_train,dt3.predict_proba(X_train)[:,1]))\n",
    "print(\"AUC on test for dt3:\",sk.metrics.roc_auc_score(y_test,dt3.predict_proba(X_test)[:,1]))\n",
    "\n",
    "print(\"AUC on train for dt10:\",sk.metrics.roc_auc_score(y_train,dt10.predict_proba(X_train)[:,1]))\n",
    "print(\"AUC on test for dt10:\",sk.metrics.roc_auc_score(y_test,dt10.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the two ensemble models: **Random Forest** and **AdaBoost**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit random forest and adaboost models\n",
    "randomforest = RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=10)\n",
    "randomforest.fit(X_train,y_train);\n",
    "\n",
    "adaboost = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators=150,\n",
    "    learning_rate=.05)\n",
    "adaboost.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on train for randomforest: 0.9999999999999999\n",
      "AUC on test for randomforest: 0.902056277056277\n",
      "AUC on train for adaboost: 0.9955986520872018\n",
      "AUC on test for adaboost: 0.8571428571428572\n"
     ]
    }
   ],
   "source": [
    "# evaluating\n",
    "print(\"AUC on train for randomforest:\",sk.metrics.roc_auc_score(y_train,randomforest.predict_proba(X_train)[:,1]))\n",
    "print(\"AUC on test for randomforest:\",sk.metrics.roc_auc_score(y_test,randomforest.predict_proba(X_test)[:,1]))\n",
    "\n",
    "print(\"AUC on train for adaboost:\",sk.metrics.roc_auc_score(y_train,adaboost.predict_proba(X_train)[:,1]))\n",
    "print(\"AUC on test for adaboost:\",sk.metrics.roc_auc_score(y_test,adaboost.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: ðŸ¤” Which model performs best?  Which models are overfit?  How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the blanks below to calculate the variable importances from the 4 untuned models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ChestPain', 'Oldpeak', 'Ca', 'MaxHR', 'Thal', 'Slope', 'ExAng',\n",
       "       'RestECG', 'Fbs', 'Chol', 'RestBP', 'Sex', 'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[np.flip(np.argsort(dt3.feature_importances_))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(24,6))\n",
    "models = {'depth-3 tree': dt3,\n",
    "          'depth-10 tree': dt10,\n",
    "          'random forest': randomforest,\n",
    "          'adaboost': adaboost} \n",
    "num_features = 10 \n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    importances = model.feature_importances_\n",
    "    order = np.argsort(importances)[-num_features:]\n",
    "    axs[i].barh(range(num_features), importances[order], tick_label=X.columns[order]);\n",
    "    axs[i].set_title(f\"Relative Variable Importance for {name}\")\n",
    "                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: ðŸ¤” How do these variable importance measures compare for these 4 models?  Which predictor is most important in general?  How is it related to `AHD`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What other approaches can be taken to measure variable importance?**\n",
    "\n",
    "One alternative for random forest:\n",
    "- Record the prediction accuracy on the *oob* samples for each tree.\n",
    "- Randomly permute the data for column $j$ in the *oob* samples, then record the accuracy again.\n",
    "- The decrease in accuracy as a result of this permuting is averaged over all trees, and is used as a measure of the importance of variable $j$ in the random forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea of re-permuting a variable and *refitting* a model to see how much more\n",
    "poorly it performs is called **permutation feature importance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is sometimes preferred to the standard feature importance approach shown above, why?\n",
    "\n",
    "Keep in mind that when two features are correlated and one of the features is permuted, the model will still have access to the feature through its correlated feature.\n",
    "\n",
    "**Q:** ðŸ¤” What is the one glaring disadvantage to the permutation approach? â²ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ELI5 ðŸ‘¶â“\n",
    "\n",
    "ELI5 is a Python package which helps to debug machine learning classifiers and explain their predictions. It provides support for several machine learning frameworks and packages such as `sklearn`, `keras` (Neural Networks), `XGBoost`, and others!\n",
    "[ELI5 Documentation](https://eli5.readthedocs.io/en/latest/overview.html)\\\n",
    "[ELI5 GitHub Repo](https://github.com/TeamHG-Memex/eli5)\n",
    "\n",
    "ELI5 stands for \"[explain like I'm five](https://www.reddit.com/r/explainlikeimfive/).\"\\\n",
    "Its visualizations show weights for each feature depicting how influential it might have been in contributing to the final prediction decision.\n",
    "\n",
    "Below we'll use the `eli5` package to calculate permutation importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation importance for the random forest\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "seed = 42\n",
    "\n",
    "perm = PermutationImportance(randomforest, random_state=seed, n_iter=10).fit(X_test, y_test)\n",
    "eli5.show_weights(perm, feature_names=X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the importances for the adaboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(adaboost,random_state=seed,n_iter=10).fit(X_test, y_test)\n",
    "eli5.show_weights(perm,feature_names=X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: ðŸ¤” How do the permutation importance measures compare to the default variable importance in the random forest?  How does the boosted model compare to the random forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A Sneak Peak at NLP (more after Thanksgiving break! ðŸ¦ƒ)\n",
    "\n",
    "Next, we'll see how ELI5 can be used to visualize feature importance for **text data.**\\\n",
    "We'll try and predict what newsgroup a post came from based on the words it contains.\n",
    "\n",
    "The motivation here is that we all have strong, relevant domain knowledge (e.g., knowing English) and so will be able to sanity check the importance placed on different words for a given classification. We can use these insights to then to determine if our model is actually learning what it should and use that information to iterate on and improve the model.\n",
    "\n",
    "Don't get too caught up on the preprocessing of the text data. What we're really interested in here are the ELI5 visualizations and how we can interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "twenty_test = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vec = CountVectorizer()\n",
    "clf = LogisticRegressionCV(max_iter=10)\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(twenty_train.data, twenty_train.target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    y_test = twenty_test.target\n",
    "    y_pred = pipe.predict(twenty_test.data)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        target_names=twenty_test.target_names)\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(clf, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above doesnâ€™t make any sense; the problem is that eli5 was not able to get feature and class names from the classifier object alone.\\\n",
    "We can provide feature and target names explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(clf, vec=vec, top=10,\n",
    "                  target_names=twenty_test.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s check prediction results on an example:\n",
    "eli5.show_prediction(clf, twenty_test.data[0], vec=vec,\n",
    "                     target_names=twenty_test.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Baseline model, improved data\n",
    "\n",
    "20 newsgroups dataset provides an option to remove footers and headers from the messages. Let's clean up the data and retrain the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=['headers', 'footers'],\n",
    ")\n",
    "twenty_test = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=['headers', 'footers'],\n",
    ")\n",
    "\n",
    "vec = CountVectorizer()\n",
    "clf = LogisticRegressionCV(max_iter=10)\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(twenty_train.data, twenty_train.target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just made the task harder and more realistic for a classifier.\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, what have the updated classifier learned?\n",
    "eli5.show_prediction(clf, twenty_test.data[0], vec=vec,\n",
    "                     target_names=twenty_test.target_names,\n",
    "                     targets=['sci.med'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pipeline improvements\n",
    "\n",
    "We can try removing stop words, applying TF-IDF, or both. Let's try that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "clf = LogisticRegressionCV(max_iter=10)\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(clf, twenty_test.data[0], vec=vec,\n",
    "                     target_names=twenty_test.target_names,\n",
    "                     targets=['sci.med'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try TF-IDF scheme.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "clf = LogisticRegressionCV(max_iter=10)\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(clf, twenty_test.data[0], vec=vec,\n",
    "                     target_names=twenty_test.target_names,\n",
    "                     targets=['sci.med'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do both stop words and TF-IDF.\n",
    "vec = TfidfVectorizer(stop_words='english')\n",
    "clf = LogisticRegressionCV(max_iter=10)\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(clf, twenty_test.data[0], vec=vec,\n",
    "                     target_names=twenty_test.target_names,\n",
    "                     targets=['sci.med'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Importance is great! It tells you what features are important in shaping the model predictions.\\\n",
    "But what is missing?\n",
    "- It does not give any measure for *how* the predictors are related to the response (positive, negative, quasi-linear, curved, interactions, etc.).\n",
    "- This is where the parametric model wins out! Inference and interpretations are much easier and is the whole point of such models.\n",
    "\n",
    "**Q:** ðŸ¤” What can we do to measure these relationships in a machine learning or nonparametric model? What did we do with k-NN? \n",
    "\n",
    "Well, we could just plot the predictions! Easy with 1 predictor, but what if we have hundreds?\n",
    "\n",
    "How do I extract the relationship between a given predictor and the response when, in the model, it is embedded in the context of the other predictors?\\\n",
    "We could hold all the other variables constant!\n",
    "\n",
    "What needs to be done algorithmically to put this in practice?\n",
    "Set the other predictors equal to *something* and only vary the predictor of interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation through Prediction Plots\n",
    "\n",
    "In a machine learning model (like ensemble methods), the association between predictors and the response are not measured directly as these models are â€˜black boxâ€™ models:\\\n",
    "Inputs (X, predictors) $\\rightarrow$ black box (sklearn, etc.) $\\rightarrow$ Outputs (Y, response)\n",
    "\n",
    "What if we care about how the predictors relate to the response? This\n",
    "is where we need to figure out what the black box is doing to\n",
    "transform the inputs into the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simplest Approach**\\\n",
    "Use predict (or better yet, predict_proba) to plot the predicted values vs. the observed values for $X_j$.\\\n",
    "What is a problem with this approach how can we fix it? (The other variables are changing!)\\\n",
    "The fix is not so easy. We cannot just fit a logistic regression model so\n",
    "easily to the predicted probabilities. Why not?\\\n",
    "An example is worth a thousand wordsâ€¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by plotting the predictions for all the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_rf_train = randomforest.predict_proba(X_train)[:,1]\n",
    "plt.scatter(X_train[['Age']],yhat_rf_train, label='train')\n",
    "yhat_rf_test = randomforest.predict_proba(X_test)[:,1]\n",
    "plt.scatter(X_test[['Age']],yhat_rf_test,marker='x', label='test')\n",
    "plt.title(\"Predicted Probabilities vs. Age from the RF in train and test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_rf_train = adaboost.predict_proba(X_train)[:,1]\n",
    "plt.scatter(X_train[['Age']],yhat_rf_train, label='train');\n",
    "yhat_rf_test = adaboost.predict_proba(X_test)[:,1]\n",
    "plt.scatter(X_test[['Age']],yhat_rf_test,marker='x', label='test');\n",
    "plt.title(\"Predicted Probabilities vs. Age from The adaboost model in train and test\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** ðŸ¤” How do the random forest and boosted models compare in the interpretation of Age with AHD?  Which is more reliable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us our approach: vary the inputs (the predictors) and see what happens to the response.\\\n",
    "If we care about the â€˜marginalâ€™ or â€˜conditionalâ€™ effect of how a specific $x$ relates to $y$, then we should vary only one predictor at a time.\\\n",
    "How should we handle the other predictors? That is to say, what\n",
    "value should we hold them at?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two general approaches holding the other predictors constant:\n",
    "1. Predict $\\hat{Y}$ at the mean (or most common) value for each of the\n",
    "other predictors, vary only the predictor you care about, $X_j$, and\n",
    "plot the predictions $\\hat{Y}$ vs. $X_j$.\n",
    "2. Predict $\\hat{Y}$ at the observed values of for all the other predictors,\n",
    "vary only the predictor you care about, $\\hat{Y}$, and plot the\n",
    "predictions $\\hat{Y}$ vs. $X_j$. Essentially this means creating a new data\n",
    "frame for each observation, and imputing all reasonable values of $X_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data frame of means to do the prediction\n",
    "means1 = X_train.mean(axis = 0)\n",
    "means_df = (means1.to_frame()).transpose()\n",
    "\n",
    "# Do the prediction at all observed ages\n",
    "Ages = np.arange(np.min(X['Age']),np.max(X['Age']))\n",
    "means_df  = pd.concat([means_df]*Ages.size,ignore_index=True)\n",
    "means_df['Age'] = Ages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots at means\n",
    "yhat_rf = randomforest.predict_proba(means_df)[:,1]\n",
    "plt.scatter(X_train['Age'],y_train)\n",
    "plt.plot(means_df['Age'],yhat_rf,color=\"red\")\n",
    "plt.title(\"Predicted Probabilities vs. Age from NN in train\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots for all observations.  And then averaged\n",
    "yhat_rfs = []\n",
    "for i in range(0,X_train.shape[0]):\n",
    "    obs = X_train.iloc[i,:].to_frame().transpose()\n",
    "    obs_df  = pd.concat([obs]*Ages.size,ignore_index=True)\n",
    "    obs_df['Age'] = Ages\n",
    "    yhat_rf = randomforest.predict_proba(obs_df)[:,1]\n",
    "    yhat_rfs.append(yhat_rf)\n",
    "    plt.plot(obs_df['Age'],yhat_rf,color='blue',alpha=0.05)\n",
    "\n",
    "plt.plot(obs_df['Age'],np.mean(yhat_rfs,axis=0),color='red',linewidth=2);\n",
    "    \n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Predicted Probabilities vs. Age from RF in train for all observations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 90% prediction interval\n",
    "plt.plot(obs_df['Age'],np.median(yhat_rfs,axis=0),color='red', label='median')\n",
    "plt.plot(obs_df['Age'],np.quantile(yhat_rfs,q=.05,axis=0),color='blue',\n",
    "         label='90% prediction interval')\n",
    "plt.plot(obs_df['Age'],np.quantile(yhat_rfs,q=.95,axis=0),color='blue')\n",
    "plt.title(\"Predicted Probabilities vs. Age from RF in train for all observations\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:**ðŸ¤” Interpret the two plots above.  What is the difference in the interpretations?  Is there any evidence of interaction effects between Age and the other predictors?  How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Explainer Model\n",
    "\n",
    "Another option is to fit an explainable model to predict the predictions of the blackbox model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>ðŸ‹ðŸ»â€â™‚ï¸ TEAM ACTIVITY:</strong> Create Surrogate Explainer Models!</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** \n",
    "- Choose either `randomforest` or `adaboost` as your model to explain\n",
    "- Get its predictions on `X_train` and `X_test`, save these as `bb_y_train` and `bb_y_test` respectively ('bb' for black box)\n",
    "- Choose a type of interpretable model (you can select one from inside the 3 modules imported above)\n",
    "- Fit this interpretable model on `X_train` and `bb_y_train`. That is, predict the original model's predictions!\n",
    "- How well does your model predict the predictions? Check the accuracy on train and test\n",
    "- Interpret your model! Can you get a global sense of how the model makes its predictions?\n",
    "- If you have time, try a second type of interpretable model\n",
    "- Add as many cells as you need and you can make use of any other imports we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LIME \n",
    "\n",
    "In the above exercise we used surrogates model to try give use a **global** explanation of our model's predictions.\\\n",
    "But we may be interested in a **local** explanation. That is, why did our blackbox model give *a particular* observation the prediction it did?\n",
    "\n",
    "A method called **LIME** was proposed in the paper [\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938v3.pdf), and it attempts to do just this. So what is LIME?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locally**: The explanation should be able to explain how the model behaves for individual observations.\\\n",
    "**Interpretable:** The explanation must be easy to understand by humans (but may depend on the target audience).\\\n",
    "**Model-agnostic:** The method should be able to explain any model.\\\n",
    "**Explanations:** self-explanatory ðŸ˜. This is the whole goal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As before, the approach is to use a directly interpretable model (e.g., a linear model) to help explain a model that is not directly interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIME ALGORITHM**\n",
    "1. Select your instance of interest for which you want to have an explanation of its black box prediction.\n",
    "2. Randomly generate points all over the feature space (sample X values from a Normal distribution inferred from the training set)\n",
    "3. Get the black box predictions for these new points.\n",
    "4. Weight each of the generated points based on their proximity to the point of interest using a kenerl function (e.g., exponential, Gaussian, etc.)\n",
    "5. Fit a *weighted*, interpretable model on the synthetic data and the original model's predictions.\n",
    "6. Explain the prediction by interpreting the local model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method can be applied to tabular data, text, and images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Toy Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig/LIME_plot.png' width='400px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, the colored regions represent either side of the original model's decision boundary.\\\n",
    "The large red marker is our point of interest.\\\n",
    "The other points are the generated data. Their color represents the *original* model's predictions and their size represents their weight based on their distance from the point of interest.\\\n",
    "The dashed line is the predictions of the interpretable surrogate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **objective** can be expressed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig/LIME_eq.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanation model for observation $x$ is the model $g$ (e.g., linear regression model) that minimizes loss $L$ (e.g., mean squared error), which measures how close the explanation is to the prediction of the original model $f$ (e.g., deep learning model), while the model complexity $\\Omega$ is kept low (e.g., prefer fewer features).\\\n",
    "$G$ is the family of possible explanations.\\\n",
    "$\\pi_x$ is a proximity measure defining a neighborhood around instance $x$ we consider for an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several LIME implementations for Python. We'll be using one simply called [lime](https://github.com/marcotcr/lime)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're working with tabular data we'll be using [LimeTabularExplainer](http://gael-varoquaux.info/interpreting_ml_tuto/content/02_why/04_black_box_interpretation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "explainer = LimeTabularExplainer(X_train.values,\n",
    "                                 feature_names=X_train.columns,\n",
    "                                 class_names = [0,1],\n",
    "                                 mode='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 109\n",
    "\n",
    "exp = explainer.explain_instance(X_train.values[idx], \n",
    "                                 randomforest.predict_proba, \n",
    "                                 num_features = 13)\n",
    "\n",
    "print('Observation #: %d' % idx)\n",
    "print('Probability(AHD) =', randomforest.predict_proba(X_train)[idx][1])\n",
    "print('True class: %s' % y_train.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the results\n",
    "exp.as_pyplot_figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the observation number and see what changes.\n",
    "idx = 209\n",
    "exp = explainer.explain_instance(X_train.values[idx], \n",
    "                                 randomforest.predict_proba, \n",
    "                                 num_features = 13)\n",
    "\n",
    "print('Observation #: %d' % idx)\n",
    "print('Probability(AHD) =', randomforest.predict_proba(X_train)[idx][1])\n",
    "print('True class: %s' % y_train.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the results\n",
    "# exp.as_list()\n",
    "exp.as_pyplot_figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a `show_in_notebook` methode but the pyplot figure one above is more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also print the explanation as list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** ðŸ¤” Interpret the LIME results above.  Do they agree with the other interpretations for the random forest model seen so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>ðŸ‹ðŸ»â€â™‚ï¸ TEAM ACTIVITY:</strong> Inspect the Worst Prediction</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction:**\n",
    "- Which observation in the test data does the random forest get *most wrong*?\n",
    "    - Think about how you would determin this\n",
    "- Use LIME to interpret this bad prediction.\n",
    "    - Do we have any insight into what is driving the mistake or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Potential Issues\n",
    "\n",
    "- The surrogate is fit to **randomly generated data**. And so interpretations can be *unstable*, changing with each run.\n",
    "- The local approximation is highly sensitive to the choice of **kernel width**.\n",
    "\n",
    "When LIME was initially proposed, the kernel used to define the neighborhood near the point of interest was selected using heuristics.\n",
    "\n",
    "<img src='fig/SHAP_kernel.png' width='700px'>\n",
    "\n",
    "<p style=\"font-size:11px\">Image by <a href=\"https://towardsdatascience.com/lime-explain-machine-learning-predictions-af8f18189bfe\">Giorgio Visani</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though there has been recent work on LIME's instability and sensitivity to kernel width. [OptiLIME](https://arxiv.org/pdf/2006.05714.pdf) proposes a more principled way.\\\n",
    "They have an open-source implementation on [Github](https://github.com/giorgiovisani/lime_stability/tree/master/OptiLIME)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Values ðŸ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Shapley value** is a solution concept in cooperative game theory. It was named in honor of [Lloyd Shapley](https://en.wikipedia.org/wiki/Lloyd_Shapley), who introduced it in 1951 and won the Nobel Prize in Economics for it in 2012. The landmark paper in which it was described is [A Value for n-person Games](https://www.rand.org/pubs/papers/P295.html) (1953).\\\n",
    "It is a method for **assigning payouts to players** depending on their **contribution** to the total payout. Players cooperate in a **coalition** and receive a certain profit from this cooperation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig/SHAP_fig.png' width=600px>\n",
    "\n",
    "<p style=\"font-size:11px\">Image by <a href=\"https://www.youtube.com/channel/UCScjF2g0_ZNy0Yv3KbsbR7Q\">DeepFindr</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each player, we'll look at all possible subsets of players in which they are included (each subset is a \"coalition\") and see how the payout changes if they are removed from the coalition.\\\n",
    "Their average contribution across all coalitions is that player's Shapley Value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes:\n",
    "- The **game** is the prediction task for a single instance of the dataset.\n",
    "- The **gain/loss** is the actual prediction for this instance minus the average prediction for all instances.\n",
    "- The **players** are the feature values of the instance that collaborate to receive the gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Four Axioms:**\n",
    "\n",
    "- **Efficiency:** the feature contributions must add up to the difference of prediction for $x$ and the average.\n",
    "- **Symmetry:** the contributions of two feature values $j$ and $k$ should be the same if they contribute equally to all possible coalitions.\n",
    "- **Dummy:** a feature $j$ that does not change the predicted value regardless of which coalition of feature values it is added to should have a Shapley value of 0.\n",
    "- **Additivity:** for combined payouts, their Shapley values are additive.\n",
    "\n",
    "The Shapley value is the *only* attribution method that satisfies the properties Efficiency, Symmetry, Dummy and Additivity, which together can be considered a definition of a fair payout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shapley Value Advantage over LIME:**\n",
    "- The Shapley value is an explanation method with a solid theory: the four axioms (efficiency, symmetry, dummy, additivity) give it a reasonable foundation.\n",
    "\n",
    "**Some Disadvantages of Shapley Values:**\n",
    "- Computationally prohibitively expensive. There are $2^p$ possible coalitions! ðŸ˜µ\n",
    "- Shapley value method always use all the features.\n",
    "- Access to the data is required if you want to calculate the Shapley value for a new data instance.\n",
    "- The Shapley value method suffers from inclusion of unrealistic data instances when features are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig/SHAP.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model.\\\n",
    "SHAP connects game theory with local explanations, uniting several previous methods.\n",
    "\n",
    "It was proposed in [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874) by Scott Lundberg and Su-In Lee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP provides multiple explainers for different kind of models:\n",
    "- **Kernel Explainer (Kernel SHAP):** Uses the Kernel SHAP method to explain the output of any function.\n",
    "- **Tree Explainer**: Uses Tree SHAP algorithms to explain the output of ensemble tree models.\n",
    "- **Gradient Explainer:** Support TensorFlow and Keras models (neural network libraries).\n",
    "- **Deep Explainer (DEEP SHAP):** Meant to approximate SHAP values for deep learning models.\n",
    "- and several others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig/SHAP_eq0.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\phi_i$: The Shapley Value for predictor $i$\n",
    "- $z'$: A 'coalition' of predictors (i.e., a subset of predictors)\n",
    "- $M$: The maximum coalition size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernel SHAP** consists of five steps:\n",
    "- Sample coalitions $z_{k}^{'} \\in \\{0, 1\\}^M, k \\in \\{1 , \\dots , K\\}$ (1 = feature present in coalition, 0 = feature absent).\n",
    "- Get prediction for each $z_{k}^{'}$ by first converting $z_{k}^{'}$ to the original feature space and then applying model $f$: $f(h_x(z_{k}^{'}))$.\n",
    "- Compute the weight for each $z_{k}^{'}$ with the SHAP kernel.\n",
    "- Fit weighted linear model.\n",
    "- Return Shapley values $\\phi_k$, the coefficients from the linear model.\n",
    "\n",
    "**Further explanation:**\n",
    "- We can create a random coalition by repeated coin flips until we have a chain of 0's and 1's. For example, the vector of (1,0,1,0) means that we have a coalition of the first and third features. The K sampled coalitions become the dataset for the regression model.\n",
    "- For tabular data, $h_x$ maps 0's to the values of another instance that we sample from the data. This means that we equate \"feature value is absent\" with \"feature value is replaced by random feature value from data\".\n",
    "\n",
    "**SHAP Kernel:**\\\n",
    "<img src='fig/SHAP_eq1.png'>\n",
    "\n",
    "where M is the maximum coalition size and |zâ€²| is the number of present features in instance zâ€².\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our weighted linear regression model, $g$:\n",
    "\n",
    "<img src='fig/SHAP_eq2.png'>\n",
    "\n",
    "We train $g$ by optimizing the following loss function $L$:\n",
    "\n",
    "<img src='fig/SHAP_eq3.png'>\n",
    "\n",
    "where $Z$ is the training data.\\\n",
    "This is the good old sum of squared errors that we usually optimize for linear models.\\\n",
    "The estimated coefficients of the model, the $\\phi_j$s are the Shapley Values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tree SHAP**\n",
    "\n",
    "- Lundberg et. al (2018) proposed TreeSHAP, a variant of SHAP for tree-based machine learning models such as decision trees, random forests and gradient boosted trees.\n",
    "- TreeSHAP was introduced as a fast, model-specific alternative to KernelSHAP\n",
    "- Compared to exact KernelSHAP, it reduces the computational complexity from $TL^2M$ to $TLD^2$ where $M$ is maximum coalition size, $T$ is the number of trees, $L$ is the maximum number of leaves in any tree, and $D$ the maximal depth of any tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires numpy=1.20.0 and numba==0.54.0\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import shap\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# train XGBoost model\n",
    "model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(X_train, label=y_train), 100)\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above explanation shows features each contributing to push the model output\n",
    "from the base value, which is the average model output over the training dataset we passed\n",
    "to the model output. Features pushing the prediction higher are shown in red,\n",
    "those pushing the prediction lower are in blue.\n",
    "\n",
    "If we take many explanations such as the one shown above, rotate them 90 degrees,\n",
    "and then stack them horizontally, we can see explanations for an entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# visualize the training set predictions\n",
    "shap.force_plot(explainer.expected_value, shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you scroll, you will see a contribution from each feature value.\n",
    "You can use the top dropdown menu to sort by similarity, output value, and\n",
    "each feature values; for example, by ChestPain. The feature values are sorted in\n",
    "asecending order. Now you can use the left dropdown menu to zoom into a\n",
    "contribution from a particular feature value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how a single feature effects the output of the model we can plot\n",
    "the SHAP value of that feature vs. the value of the feature for all the\n",
    "examples in a dataset. Since SHAP values represent a feature's responsibility\n",
    "for a change in the model output, the plot below represents the change in\n",
    "predicted probability of having heart disease as `age`\n",
    "changes. Vertical dispersion at a single value of `age` represents interaction\n",
    "effects with other features. To help reveal these interactions dependence_plot\n",
    "automatically selects another feature for coloring. In this case coloring by ChestPain highlights that age has a much higher impact on the predicted probability of heart disease for those with chest pain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use dependence_plot function to create a dependence plot to show the effect\n",
    "# of a single feature across the whole dataset.\n",
    "shap.dependence_plot(\"Age\", shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an overview of which features are most important for a model we can\n",
    "plot the SHAP values of every feature for every sample. The plot below sorts\n",
    "features by the sum of SHAP value magnitudes over all samples, and uses SHAP\n",
    "values to show the distribution of the impacts each feature has on the model\n",
    "output. The color represents the feature value (red high, blue low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use summary_plot function to summarize the effects of all the features.\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also just take the mean absolute value of the SHAP values for each\n",
    "# feature to get a standard bar plot:\n",
    "\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model agnostic example with [KernelExplainer](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.KernelExplainer.html)\n",
    "\n",
    "Kernel SHAP uses a specially-weighted local linear regression to estimate SHAP values for *any* model. Does that sound familiar?\\\n",
    "The computed importance values are Shapley values from game theory and also coefficents from a local linear regression.\\\n",
    "Below is a simple example for explaining a multi-class SVM on the classic iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "\n",
    "# train a SVM classifier\n",
    "# X_train,X_test,Y_train,Y_test = train_test_split(*shap.datasets.iris(), test_size=0.2, random_state=0)\n",
    "svm = sklearn.svm.SVC(kernel='rbf', probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# use Kernel SHAP to explain test set predictions\n",
    "explainer = shap.KernelExplainer(svm.predict_proba, X_train, link=\"logit\")\n",
    "shap_values = explainer.shap_values(X_test, nsamples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SHAP values for the first a specific test observation\n",
    "obs = 5\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][obs,:], X_test.iloc[obs,:], link=\"logit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_test[obs:obs+1])\n",
    "y[obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.Chol.mean(), X_train.MaxHR.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>ðŸ‹ðŸ»â€â™‚ï¸ TEAM ACTIVITY:</strong> Inspect the Worst Prediction</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction:**\n",
    "- Which observation in the test data does the model predict correctly and most confidently?\n",
    "    - There could be ties. Pick just one.\n",
    "- Use `force_plot` to interpret this confident prediction.\n",
    "    - Do we have any insight into what is driving the decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We looked at ELI5, LIME, and SHAP as a way to explain machine learning models in model-agnostic way.\\\n",
    "But there remains a tension between explainability and accuracy of machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Interpretable ML: https://christophm.github.io/interpretable-ml-book\n",
    "\n",
    "ELI5: https://eli5.readthedocs.io/en/latest/index.html\n",
    "\n",
    "LIME: https://github.com/marcotcr/lime\n",
    "\n",
    "SHAP: https://github.com/slundberg/shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**FIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
