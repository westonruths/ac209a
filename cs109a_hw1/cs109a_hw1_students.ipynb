{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"padding-top: 25px;padding-bottom: 25px;text-align: left; padding-left: 10px; background-color: #DDDDDD; \n",
    "    color: black;\"> <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science </h1>\n",
    "\n",
    "## Homework 1: Data Collection, Parsing, and Quick Analyses\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2021**<br/>\n",
    "**Instructors**: Pavlos Protopapas and Natesh Pillai<br/>\n",
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2021-CS109A/master/themes/static/css/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Overview \n",
    "\n",
    "In this homework, your goal is to learn how to acquire, parse, clean, and analyze data. Toward this goal, we will address certain questions about COVID, and you will scrape data directly from a website. For the remainder of the semester, we will provide you data files directly; however, since real-world problems often require gathering information from a variety of sources, including the Internet, web scraping is a highly useful skill to have.\n",
    "\n",
    "### Instructions\n",
    "- To submit your assignment, follow the instructions given in Canvas.\n",
    "\n",
    "### Learning Objectives\n",
    "- Get started using [Jupyter Notebooks](https://jupyter.org/), which are incredibly popular, powerful, and will be our medium of programming for the duration of CS109A and CS109B.\n",
    "- Become familiar with how to access and use data from various sources (i.e., web scraping and directly from files).\n",
    "- Gain experience with data exploration and simple analysis.\n",
    "- Become comfortable with [pandas](https://pandas.pydata.org/) as a means of storing and working with data.\n",
    "- Reflect on what further analysis you may wish to do with this data. For example, given the material we've covered so far, what *more* do you wish you had the ability to do (e.g., modelling, prediction, etc). That is, think about questions you may have about the data, and try to imagine what types of tools you might need to help answer your questions.\n",
    "\n",
    "### Notes\n",
    "- Exercise **responsible scraping**. Web servers can become slow or unresponsive if they receive too many requests from the same source in a short amount of time. In your code, use a delay of 2 seconds between requests. This helps to not get blocked by the target website -- imagine how frustrating it would be to have this occur. Section 1 of this homework involves saving the scraped web pages to your local machine. Thus, after completing Section 1, you do not need to re-scrape any of the pages, unless you wish to occasionally grab the latest data. \n",
    "\n",
    "- <span style='color:purple'>**Web scraping requests can take several minutes**</span>. This is another reason why you should not wait until the last minute to do this homework.\n",
    "- As you run a Jupyter Notebook, it maintains a running state of memory. Thus, <span style='color:purple'>the order in which you run cells matters</span> and plays a crucial role; it can be easy to make mistakes based on *when* you run different cells as you develop and test your code. Before submitting every Jupyter Notebook homework assignment, be sure to restart your Jupyter Notebook and run the entire notebook from scratch, all at once (i.e., \"Kernel -> Restart & Run All\"). Just make sure to not re-run the time intensive tasks unnecessarily. In this notebook for example, you could declare a variable to act as a 'setting' and use some controll logic to prevent a re-scrap from happening when not desired.\n",
    "\n",
    "- We will be working with COVID data. COVID has impacted everyone in the world, and naturally some people have been greatly more affected than others. We, the teaching staff, are sensitive to this, empathize, and understand that working with COVID data may be unsettling to some. We apologize for any discomfort this may cause. Our intent with this assignment is purely pedagogical, and we'd like to remind students that data science and machine learning can be used to provide insights that can be used for good and invoke change. Toward this goal, parts of the homework are intended to shed light on the unfortunate, widespread inequality that exists. So, while this data may be unsettling, our aim is for the learned skills addressed here -- and in all future assignments -- to provide you with knowledge and confidence to do good work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Obtaining Data (17 points)\n",
    "\n",
    "For any given situation or scenario that we wish to understand, we will rely on having relevant data. Here, we are interested in the degree to which the SARS-CoV-2 virus has affected United States citizens (SARS-CoV-2 is the virus that causes the COVID-19 disease). The Centers for Disease Control and Prevention (CDC) provides relevant data from USAFacts.org that includes the number of confirmed COVID-19 cases on a per-county basis. Visit https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/. At the bottom of the web page, in a blue table, you should see a list of every state, each of which has its own web page.\n",
    "\n",
    "In this exercise, we will focus on automating the downloading of each state's data with [Requests](https://docs.python-requests.org/en/master/) and then manipulating it with [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). \n",
    "\n",
    "But first, as we will do for every Jupyter Notebook, let's import necessary packages that we will use throughout the notebook (i.e., run the cell below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle # for loading a dictionary from disk\n",
    "from typing import Optional # typehint that value can also be None\n",
    "\n",
    "# NOTE: files will be saved to this directory, so you need to ensure\n",
    "# that it exists on your system first (it should be visible from the\n",
    "# directory of where you are running this Notebook file)\n",
    "# i.e.,\n",
    "# >> ls\n",
    "# cs109a_hw1_student.ipynb\n",
    "# data/\n",
    "# state_data/\n",
    "state_dir = \"state_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define this for convenience, as every state's url begins with this prefix\n",
    "base_url = 'https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 1.1 [1 pt]: Fetching Website data via Requests</b>\n",
    "\n",
    "Fetch the web page located at `base_url` and save the request's returned object (a Response object) to a variable named `home_page`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 1.2 [2 pts]:</b> In the cell below:\n",
    "    \n",
    "- Write a line of code that prints to the screen the status of `home_page` (the web page's returned object). You should receive a code of 200 if the request was successful; then,\n",
    "\n",
    "- **When working with Jupyter Notebooks, avoiding unnecessarily long output in is essential.** Write code that prints the first 10,000 characters from the contents of `home_page` and [enable scolling output for the cell](https://www.youtube.com/watch?v=U4usAUZCv_c&t=1s).</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 1.3 [1 pt]:</b>\n",
    "    \n",
    "In the cell below, create a new BeautifulSoup object that parses the `home_page` as an HTML document (can be done with 1 line of code)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 1.4 [8 pts]:</b>\n",
    "    \n",
    "In the cell below, write code that uses the BeautifulSoup object to parse through the home page in order to extract the link for every state. Feel free to use [Regular Expressions]('https://docs.python.org/3/library/re.html'), in conjunction with any BeautifulSoup parsing. Specifically, the goal is to populate a `state_urls` [dictionary]('https://docs.python.org/3/tutorial/datastructures.html#dictionaries') by setting each key to be the state name and the value to be the full URL. When complete, there will be 51 keys (50 states + 1 for DC).\n",
    "\n",
    "### AS A CRITICAL EXAMPLE:\n",
    "Within `state_urls`, one of your <key, value> pairs should be:\n",
    "\n",
    "``\"District of Columbia\" : \"https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/state/district-of-columbia\"``\n",
    "\n",
    "The casing here is **incredibly** important because later, in Exercise 4, you will merge your data with another dataset that has casing of this form. Thus, our key here should be `District of Columbia` and not `District Of Columbia` or `district-of-columbia`.\n",
    "\n",
    "\n",
    "**NOTES:**\n",
    "- There are _many_ solutions, but you may find it easiest to use Regular Expression(s)\n",
    "- Pay attention to the casing example above, so that your later exercises go smoothly.\n",
    "- Some HTML tag attributes may change over time. It your code stops working, make sure you are not targeting such ephemeral elements ('jss' class attributes are a common culprit)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_urls = {}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to help ensure your formatting is correct and has 51 <key, value> pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECK\n",
    "if len(state_urls.keys()) != 51 or \\\n",
    "state_urls[\"District of Columbia\"] != \"https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/state/district-of-columbia\":\n",
    "    print(\"** 1.4 is incorrect\")\n",
    "else:\n",
    "    print(\"** 1.4 might be correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to use the data without having to re-download it every time. So, let's save each webpage to our local hard drive. **NOTE: It's probably okay to download all of the state web pages a few times a day, but it's safer to keep it to a minimum.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 1.5 [5 pts]:</b>\n",
    "    \n",
    "In the cell below, we will iterate through all <key, value> items in `state_urls`. Your job is to make a web request for each URL and save the **contents** out to a file on your hard drive (use `state_dir`, defined above, as the prefix to the path.) \n",
    "\n",
    "**NOTES:**\n",
    "- **Leave a 2 second pause between requests**\n",
    "- You should be saving to a file the actual content of the webpage, not a BeautifulSoup object. That is, you should be able to open the saved files in an editor and see the HTML code, just as you could if you were to view the webpage in your browser and click 'View Page Source'.\n",
    "- See [official Python documentation](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) for details on how to read/write files to disk\n",
    "- You should have saved 51 different files to your hard drive.\n",
    "- **Once you have written the files you can comment out this cell. This will save time and prevent you from making unnecessary requests when you restart the kernel & re-run all cells in the noteboook before submitting (as you should!)**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 (5 pts) -- save each webpage to disk\n",
    "for state, url in state_urls.items():\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE\n",
    "    \n",
    "    sleep(2) # LEAVE THIS IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Loading and Exploring Data (22 pts)\n",
    "Now, let's actually use the data! Fortunately, it's saved to our local machine, so we don't need to re-crawl the data every time we wish to access it. We want you to understand that [pandas](https://pandas.pydata.org/) is a library of useful data structures and operations, but we also wish to remind you that it isn't magic and it isn't the _only_ way to do Data Science; it's just a tool to help, and you could do the same operations without pandas. Thus, here we ask you to perform a few operations without using pandas, and then in Exercise 3 we will use pandas.\n",
    "\n",
    "**Terminology Notice:** In the United States, every state is comprised of many **counties.** You can think of a **county** as being a pretty large district. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the cell below to construct `state_info`\n",
    "This is an example of a Python [list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_info = [(state, state_dir + state) for state in state_urls.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 2.1 [10 pts]: Parsing and storing data</b>\n",
    "    \n",
    "Complete the `load_covid_data()` function, which:\n",
    "\n",
    "- Takes as input `state_info`, which is a list of [tuples](https://docs.python.org/3.3/library/stdtypes.html?highlight=tuple#tuple): (state name, path to the corresponding file)\n",
    "- Parses the contents of the file and extracts for **each county**:\n",
    "    - 7 day average case\n",
    "    - 7 day average deaths\n",
    "    - \\# of confirmed cases (total)\n",
    "    - \\# of deaths\n",
    "    - Stores the above 4 pieces of data above as well as **population** in a **non-pandas** data structure named `covid_data` **for every county across every state**\n",
    "- Returns `covid_data`\n",
    "    <font color='blue'>\n",
    "\n",
    "\n",
    "**NOTES:**\n",
    "- **Attention: the population variable not in `state_info`. More on info on where to get this value is found in the green block below**\n",
    "- To be clear, as of September 7, 2021, the webpage for Alabama currently lists 67 counties. District of Columbia has 1 county, and Wyoming has 23. Here we are asking you to store in `covid_data` *all counties* across every state. So, later, if we were wished to access just Wyoming's information, you could easily retrieve such for each of its 23 counties, or the info for any of the 67 counties in Alabama.\n",
    "- `covid_data` **must not be a PANDAS data structure;** it must use a combination of lists and/or dictionaries. It's up to you to decide how to organize this, e.g., a lists of lists of lists, or a list of dictionaries, or a dictionary of dictionaries, or a dictionary of lists of lists, etc. A guiding decision should be ease of access for computing basic stats (Exercises 2.2, 2.3, and 2.4)\n",
    "- For the duration of our using this data for the homework, be sure to **properly store the data with the correct data types;** that is, counts should be represented as Integers and rates should be represented as Floats. For example:\n",
    "    - \\# of confirmed cases (total) should be an **Integer**\n",
    "    - \\# of deaths should be an **Integer**\n",
    "    - \\# of confirmed cases (per 100k) should be a **Float** (we haven't created this feature yet!)\n",
    "    - 7 day average cases should be an **Integer** (you'd think an average should be a float but the values you scrapped were rounded to the nearest int)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style='background-color:lightgreen;padding:15px'>\n",
    "    <strong>Injecting population data</strong>\n",
    "    \n",
    "\n",
    "The table on usafacts.org you've just scrapped originally had additional columns related to county population. But these have recently been removed! We'd like you to be able to utilize the population data in the following section but also use up-to-date COVID data (so the [Internet Archive](https://archive.org/) was not an option). And, though this information is available elsewhere on usafacts.org, we've decided that you've already done enough web scraping for one HW. So below we've provided a [kludge](https://en.wikipedia.org/wiki/Kludge#Computer_science).\n",
    "    \n",
    "`population_dict` is a nested dictionary. The keys are states whose values are _themselves_ dictionaries. Those '_inner_' dictionaries' keys are counties and their values are populations. It looks like this:\n",
    "```python\n",
    "{'Alabama': {'Autauga County': 55869,\n",
    "             'Baldwin County': 223234,\n",
    "           ...\n",
    "'Wyoming': {'Albany County': 38880,\n",
    "            'Big Horn County': 11790,\n",
    "            ...\n",
    "```\n",
    "\n",
    "To get at a population you could use double dictionary indexing like `population_dict['Alabama']['Autauga County']`\n",
    "\n",
    "But not all of the counties you've scrapped have population data in this dictionary. So we've provided a helper function, `get_pop`, that will return `None` if the county data was not found. Use `get_pop` to inject popoulation data into your `covid_data` as you build it up in the `load_covid_data` function you'll implement below.\n",
    "    \n",
    "**Final Note: you should _ignore counties with missing population data or populations of 0_. Simply do not add them to `covid_data` as it is constructed.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load additional county population data as a nested dictionary\n",
    "# you can read about this strange .pkl 'pickle' file here\n",
    "# https://docs.python.org/3/library/pickle.html\n",
    "with open('population.pkl', 'rb') as f:\n",
    "    population_dict = pickle.load(f)\n",
    "\n",
    "# not sure what's happening with the data types in the function header?\n",
    "# check out: https://docs.python.org/3/library/typing.html#module-typing\n",
    "def get_pop(state: str, county: str) -> Optional[int]:\n",
    "    '''\n",
    "    returns population of country, state (int)\n",
    "    If county or state not found, returns None\n",
    "    Example: get_pop('Alabama', 'Autauga County')\n",
    "    '''\n",
    "    try:\n",
    "        return population_dict.get(state).get(county)\n",
    "    except AttributeError:\n",
    "        print('incorrect state name!')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_covid_data(state_info):\n",
    "    covid_data = {}\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE\n",
    "    return covid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = load_covid_data(state_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "population_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 2.2 [4 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_county_stats()` function, which calculates:\n",
    "1. The single county (and the state to which it belongs) that has the **lowest rate** of COVID cases per 100k people\n",
    "2. The single county (and the state to which it belongs) that has the **highest rate** of COVID cases per 100k people\n",
    "   \n",
    "**NOTES:**\n",
    "- Place your resulting variables within the blanks of the `print()` statements that we provide\n",
    "- These values you report should be Floating point numbers (e.g., 3.4), not Integers (e.g., 3).\n",
    "- If there are ties, return any one of the tied counties (see if you can do it in an unbiased way!)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_county_stats(covid_data):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_county_stats(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 2.3 [4 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_state_deaths()` function, which calculates:\n",
    "1. The state that has the **lowest number** of deaths\n",
    "2. The state that has the **highest number** of deaths\n",
    "\n",
    "**NOTES:**\n",
    "- Place your resulting variables within the blanks of the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "- These values you report should be Integers, not Floating point numbers.\n",
    "- If there are ties, return any of the tied states\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_state_deaths(covid_data):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_state_deaths(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 2.4 [4 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_state_deathrate()` function, which calculates:\n",
    "1. The state that has the **lowest rate** of deaths based on its entire population\n",
    "2. The state that has the **highest rate** of deaths based on its entire population\n",
    "\n",
    "**NOTES:**\n",
    "- To calculate a state's population, we are asserting that is sufficient to sum the population over all counties, and that each county's population can be calculated simply from the data fields stored within `covid_data`.\n",
    "- **If a county has reported 0 COVID cases,** then we should ignore this county as we estimate its county population. Thus, that county would contribute 0 to its state population total.\n",
    "- Round your results to the a single person (e.g., \"1 out of every 2703 people has died\" not 2703.4)\n",
    "- Place your resulting variables within the blanks of the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_state_deathrate(covid_data):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_state_deathrate(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PANDAS (36 pts)\n",
    "What if we wanted to observe more than just the single-most extreme counties and states? What if we wanted to inspect all states, after having sorted the data by some feature? As you saw in the above exercises, doing the most basic analytics is possible, but it can quickly become cumbersome. As we learned in class, PANDAS is a great library that provides data structures that are highly useful for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 3.1 [10 pts]: Converting to PANDAS</b>\n",
    "\n",
    "In Exercise 2, we worked with `covid_data`, which is comprises of some combination of lists and/or dictionaries.\n",
    "\n",
    "Complete the `convert_to_pandas()` function, which converts `covid_data` to a PANDAS DataFrame, whereby:\n",
    "- Each row corresponds to a unique county\n",
    "- The 4 columns are:\n",
    "    - county\n",
    "    - state\n",
    "    - \\# total covid cases (Integer)\n",
    "    - \\# case per 100k (Integer)\n",
    "    - \\# covid deaths (Integer)\n",
    "- The columns should be titled **exactly** as listed above\n",
    "\n",
    "**NOTE:**\n",
    "- If there exists multiple counties with the same name, each of which belonging to a different state, then there should be a distinct row for each.\n",
    "- The 2 columns that correspond to COVID counts should all be Integers (e.g., 1498), not Floating point digits (e.g., 1498.0)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pandas(covid_data):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE\n",
    "    return covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = convert_to_pandas(covid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 3.2 [5 pts]: Simple analytics</b>\n",
    "\n",
    "Complete the `calculate_county_stats2()` function, **which should obtain identical information (other than ties) as problem 2.2, but now using the PANDAS `covid_df` DataFrame.**\n",
    "\n",
    "That is, it should calculates:\n",
    "1. the single county (and the state to which it belongs) that has the **lowest rate** of COVID cases per 100k people\n",
    "2. the single county (and the state to which it belongs) that has the **highest rate** of COVID cases per 100k people\n",
    "\n",
    "**NOTES:**\n",
    "- If there are ties, return any of the tied counties\n",
    "- Place your resulting variables within the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "- The values you report should be Floating point numbers (e.g., 3.4), not Integers (e.g., 3).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_county_stats2(covid_df):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_county_stats2(covid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 3.3 [5 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_state_deaths2()` function, **which should obtain identical information as problem 2.3 (other than ties), but now using the PANDAS `covid_df` DataFrame.**\n",
    "1. the state that has the **lowest number** of deaths\n",
    "2. the state that has the **highest number** of deaths\n",
    "\n",
    "**NOTES:**\n",
    "- If there are ties, return any of the tied states\n",
    "- Place your resulting variables within the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "- The values you report should be Integers, not Floating point numbers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_state_deaths2(covid_df):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_state_deaths2(covid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Exercise 3.4 [5 pts]: Simple analytics</b>\n",
    "    \n",
    "Complete the `calculate_state_deathrate2()` function, **which should obtain identical information as problem 2.4, but now using the PANDAS `covid_df` DataFrame.** That is, return:\n",
    "\n",
    "1. The state that has the **lowest rate** of deaths based on its entire population\n",
    "2. The state that has the **highest rate** of deaths based on its entire population\n",
    "\n",
    "**NOTES:**\n",
    "- Just as in, 2.4, to calculate a state's population, we are asserting that is sufficient to sum the population over all counties -- and that each county's population can be calculated simply from the data fields stored within `covid_data`.\n",
    "- Just as in 2.4, counties with 0 COVID cases should contibute 0 to the total population of the state.\n",
    "- Round your results to the a single person (e.g., \"1 out of every 2703 people has died\" not 2703.4)\n",
    "- Place your resulting variables within the blanks of the `print()` statements that we provide (don't just manually type your textual answers in the blanks)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_state_deathrate2(covid_df):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE\n",
    "    #print(____ + \" has the lowest COVID death rate; 1 out of every \" + ____ + \" people has died\")\n",
    "    #print(____ + \" has the highest COVID death rate; 1 out of every \" + ____ + \" people has died\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_state_deathrate2(covid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are highly alarming and tragic statistics, and doing calculations like this can really put the severity of the virus into a grounded perspective. In order to perfectly understand the virus and its spread, everyone would be tested and we would have contact tracing. Without getting into socio-political issues, our point is that (1) we wish to better understand the virus' effects; (2) naturally, any real-world data is messy, and thus we will never have _perfect_ data.\n",
    "\n",
    "\n",
    "Let's now attempt to understand _some_ of the uncertainty around our COVID data. It's reasonable to believe that the # of COVID deaths is fairly reliable. That is, there are inevitably some false negatives -- people who died of COVID but were not accounted for, as other conditions were listed as the cause. However, the number of false positives is probably minimal -- if someone was denoted as dying from COVID, it's probably true. It's also the case that every disease has a mortality rate. For example, if 1,000 randomly-selected people contracted COVID, $N\\%$ of them will die. We'd imagine that this percentage should be pretty constant throughout all people in the United States. Of course, we can think of reasons for this rate to not be perfectly consistent, as some people are at higher risk (e.g., older folks, people with pre-existing conditions, etc). Yet, we can imagine that this natural *variance* in the population to be fairly uniform throughout the USA at large. To this end, if all counties were equal in their **testing**, we ought to see a consistent ratio between: (a) the # of people who died from COVID; and (b) the # of people who tested positive for COVID. Within the medical domain, this ratio is referred to as the `case_fatality_rate`. For example, if 750 people tested positive for COVID, and 75 of those people died, then our `case_fatality_rate` would be 0.1 (meaning 10%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 3.5 [5 pts]: Further analytics</b>\n",
    "    \n",
    "Complete the `add_death_stats()` function below, which should add 3 new columns:\n",
    "- `case_fatality_rate`\n",
    "- `# covid deaths per 100k` and\n",
    "- `population`\n",
    "\n",
    "And return the updated DataFrame **sorted by `case_fatality_rate` in ascending order** \n",
    "\n",
    "**NOTES:**\n",
    "\n",
    "- `add_death_stats()` should return a new DataFrame that has 8 columns:\n",
    "    - county\n",
    "    - state\n",
    "    - population\n",
    "    - \\# total covid cases\n",
    "    - \\# covid cases per 100k\n",
    "    - \\# covid deaths\n",
    "    - \\# covid deaths per 100k\n",
    "    - case_fatality_rate\n",
    "- DataFrame should be sorted by `case_fatality_rate` in ascending order\n",
    "- Again, the values for `case_fatality_rate` should be < 1. A value of 1 would mean that 100% of people who tested positive for COVID also died.\n",
    "- `# covid deaths per 100k` is simply defined as the # of COVID deaths for every 100,000 people. We calculate this on a per-county basis.\n",
    "- Make sure you inspect your results thoroughly. You may have to address the results of divisions by zero (or prevent these divisions in the first place). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_death_stats(covid_df):\n",
    "    \n",
    "    # can add an infintesimal or fillna after the fact to handle nans from divide by 0.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE\n",
    "    return covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_updated = add_death_stats(covid_df)\n",
    "covid_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Reflection:</b> Data Analysis allows us to better understand a system or scenario.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 3.6.1 [2 pts] Trends</b>\n",
    "    \n",
    "Having looked at the results from Exercises 3.3, 3.4, and 3.5, what are some trends you've noticed and any conclusions you have? (2-3 sentences)?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#F6FEFA;padding:15px'>\n",
    "\n",
    "**your answer here**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 3.6.2 [2 pts]: Data Reliability</b>\n",
    "    \n",
    "Having looked at the results from Exercise 3.5 (i.e., `covid_updated` DataFrame), do you think the original data is reliable and accurate? Are there any potential biases that you're aware of or concerned about? Please explain (3-5 sentences).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#F6FEFA;padding:15px'>\n",
    "\n",
    "**your answer here**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 3.6.3 [1 pt]: Relationships Between Variables</b>\n",
    "    \n",
    "If a county has 15 confirmed deaths, how many cases would you expect? What would you expect its population to be? Explain why (1-2 sentences in total)?\n",
    "\n",
    "**NOTE:** For this question, we aren't evaluating the accuracy of your answer but your thought-process and reasoning.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#F6FEFA;padding:15px'>\n",
    "\n",
    "**your answer here**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 3.6.4 [1 pt]: Further Questions</b>\n",
    "    \n",
    "What further questions do you wish to answer about COVID, including ones that may not be possible to answer from this data alone (e.g., Is there a correlation between the average age of people in a county and the # of COVID deaths)? Write at least 3 of your questions.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#F6FEFA;padding:15px'>\n",
    "\n",
    "**your answer here**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. MORE DATA (25 pts)\n",
    "In order to better understand how COVID (and the testing thereof) has impacted our world, we could look at how it relates to demographics, income, education, health, and political voting. For this exercise, we will make use of `election2020_by_county.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.1 [4 pts]: Load more data</b>\n",
    "\n",
    "Complete the `merge_data()` function, which should:\n",
    "1. First, load `election2020_by_county.csv` as a new DataFrame.\n",
    "2. Then, using the state and county names (case-sensitive) in both DataFrames, merge this new DataFrame with your existing `covid_updated`.\n",
    "3. Return the merged DataFrame\n",
    "\n",
    "The returned `merged` DataFrame should contain all 8 columns from `covid_updated`:\n",
    "- county\n",
    "- state\n",
    "- \\# total covid cases\n",
    "- \\# covid cases per 100k\n",
    "- \\# covid deaths\n",
    "- population\n",
    "- \\# covid deaths per 100k\n",
    "- case_fatality_rate\n",
    "\n",
    "along with these 15 columns from `election2020_by_county.csv`:\n",
    "- hispanic\n",
    "- minority\n",
    "- female\n",
    "- unemployed\n",
    "- income\n",
    "- nodegree\n",
    "- bachelor\n",
    "- inactivity\n",
    "- obesity\n",
    "- density\n",
    "- cancer\n",
    "- voter_turnout\n",
    "- voter_gap\n",
    "- trump\n",
    "- biden\n",
    "\n",
    "**NOTES:**\n",
    "- We are dropping two columns from `election2020_by_county.csv`:\n",
    "    - fipscode\n",
    "    - population\n",
    "- Do not attempt to manually fix any of the state or county names. That is, **our merging should require the state and county names to be identical (case-sensitive) between the two DataFrames.** If there is a discrepancy between the two, do not worry about adjusting these names to find a perfect match.\n",
    "\n",
    "**HINT:** there are many ways to solve this, but you may find the [pandas.merge()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) function can be really helpful\n",
    "\n",
    "**EXTRA INFORMATION:** In case you're wondering what the different features/columns are in `election2020_by_county.csv`:\n",
    "\n",
    "- state: the state in which the county lies\n",
    "- fipscode: an ID to identify each county\n",
    "- county: the name of each county\n",
    "- population: total population\n",
    "- hispanic: percent of adults that are hispanic\n",
    "- minority: percent of adults that are nonwhite\n",
    "- female: percent of adults that are female\n",
    "- unemployed: unemployment rate, as a percent\n",
    "- income: median income\n",
    "- nodegree: percent of adults who have not completed high school\n",
    "- bachelor: percent of adults with a bachelor’s degree\n",
    "- inactive: percent of adults who do not exercise in their leisure time\n",
    "- obesity: percent of adults with BMI > 30\n",
    "- density: population density, persons per square mile of land\n",
    "- cancer: prevalence of cancer per 100,000 individuals\n",
    "- voter_turnout: percentage of voting age population that voted\n",
    "- voter_gap: percentage point gap in 2020 presidential voting: trump-briden\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(covid_updated, filepath):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE\n",
    "    #return ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below (no changes necessary) to execute your code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_data(covid_updated, 'election2020_by_county.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the merging requires exact matching between the two DataFrames' `state` and `county` columns. Thus, some mismatches will occur, yielding our `merged` DataFrame to have fewer rows than `covid_updated` and `election2016_by_county.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Data Construction / Understanding</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.2.1 [1 pt]: Lost Rows</b>\n",
    "    \n",
    "Compared to `covid_updated`, how many rows were lost during this merging process to create `merged`? Running the cell below should print to the screen your answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.2.2 [2 pts]: Lost Counties</b>  \n",
    "\n",
    "List the county and state of *at least 3* such rows that exist in `covid_updated` but didn't make it into `merged`. Running the cell below should print to the screen your answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.2.3 [2 pts]: Suggested Fixes</b>\n",
    "   \n",
    "If we needed to be highly thorough and needed comprehensive data coverage, do you have any suggestions on how we could quickly, soundly fix most or all of them? (Write 2-3 sentences.)\n",
    "    \n",
    "<b>NOTE: Please do not actually fix these mismatches; for this Exercise, it's okay that the `merged` DataFrame is smaller than `covid_updated`</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#F6FEFA;padding:15px'>\n",
    "\n",
    "**your answer here**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This past example demonstrates how easy it is for data to become messy. It also shows the importance of paying close attention to your data in order to understand what you are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `case_fatality_rate` column can be viewed as an approximation of how effective and thorough *COVID testing* is for a given county.\n",
    "\n",
    "Our `# covid deaths` column can be viewed as an extreme indication of how severe *COVID* has impacted a given county.\n",
    "\n",
    "Our `# covid cases per 100k` column be viewed as middle-ground between the two aforementioned features. That is, it measures the impact of the disease and is influenced by the thoroughness of COVID testing.\n",
    "\n",
    "Using these three informative features, we can inspect how impacted each county is, while correlating this with other features of each county, such as income-level, health metrics, demographics, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.3 [2 pts]: Cleaning the data</b>\n",
    "\n",
    "Before we do any further analysis, we first notice that some counties haven't encountered a single COVID death (usually ones with very small populations), thus providing us with little information. Write code in the cell below to update the `merged` DataFrame so that all rows with 0 deaths are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `.describe()` allows us to quickly see summary statistics of our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the information reported from `.describe()`, we can imagine dividing our DataFrame into 4 separate bins, based on the distribution for any given feature. Specifically, based on a particular feature:\n",
    "- the $1^{st}$ bin will be the data that has values between the **min** and **25%**\n",
    "- the $2^{nd}$ bin will be the data that has values between **25%** and **50%**\n",
    "- the $3^{rd}$ bin will be the data that has values between **50%** and **75%**\n",
    "- the $4^{th}$ bin will be the data that has values between **75%** and **max**\n",
    "\n",
    "<div class='exercise'><b>Exercise 4.4 [3 pts]: Partitioning our data</b>\n",
    "    \n",
    "Complete the `partition_df()` function, which takes as input:\n",
    "- DataFrame to work with\n",
    "- feature (e.g., obesity) to filter by\n",
    "- minimum value\n",
    "- maximum value\n",
    "\n",
    "and outputs:\n",
    "- a subset of the DataFrame that has values between the passed-in minimum and maximum values (inclusively) for the passed-in feature.\n",
    "\n",
    "For example, if we called `partition_df(merged, 'obesity', 30, 45)`, it should return a subset of the `merged` DataFrame that has obesity values between 30 and 45 (and including the boundary values of 30 and 45).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_df(df, column_name, minv, maxv):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.5: [4 pts] Exploratory Data Analysis</b>\n",
    "    \n",
    "Identify a few features that you're interested in, and inspect if there's any correlation with the COVID data. Specifically, simply run your `partition_df()` function below, many times, each with a different subset of the data -- select a range of values and a particular feature. For example, if I'm interested in __cancer__, I could look at the 4 quartiles (per `.describe()`) and use those ranges of values as I repeatedly execute `partition_df()`. For this exercise, after running the function several times, **write 3-5 sentences about any patterns or correlations you noticed or didn't notice but expected to find.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE\n",
    "\n",
    "#partition_df(merged, 'your feature here', your_min_value, your_max_va).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#F6FEFA;padding:15px'>\n",
    "\n",
    "**your answer here**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.describe()` provides these nice summary statistics over any portion of data that we give it. Instead of iteratively inspecting several subsets of the data, let's actually split our DataFrame into new categories; instead of representing all features by floating point numbers, let's create new _categorical_ names for feature(s) based on their numbers. The code below does just this. It creates a new column, `income group` that has 4 possible values, each one corresponding to a quartile of the original `income` values. \n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 38000, 45000, 52000, 200000]\n",
    "names = ['income-group-1', 'income-group-2', 'income-group-3', 'income-group-4']\n",
    "d = dict(enumerate(names, 1))\n",
    "merged['income group'] = np.vectorize(d.get)(np.digitize(merged['income'], bins))\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.6 [5 pts]: Aggregate data</b>\n",
    "    \n",
    "    \n",
    "Write code in the cell below to group (and display) the data according to the 4 income groups. Also, while we will still keep the same columns (i.e, features), the values of each should now represent the __average__ value of all rows that were subsumed in the making of the aggregate income-group. Your resulting DataFrame should have just 4 rows (income-group-1, income-group-2, income-group-3, income-group-4). See example in the cell below.\n",
    "\n",
    "\n",
    "Since every feature (except for `# total cases`, `# covid deaths`, and `population`) was already an average value corresponding to a particular __county__, when we aggregate our data by income groups, we are effectively taking an average of an average. Many counties are being aggregated for each income-group row. This approach isn't as accurate as possible; it would be more accurate if we re-adjusted every value so that it was truly an average that was based on the total __population__ of all counties that are subsumed within a given income-group row. That's okay, though. An average of averages will suffice for the purpose of this exercise. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: If our `merged` DataFrame were\n",
    "# COUNTY    INCOME GROUP    BACHELOR ... (other columns, too)\n",
    "#   A            2             50\n",
    "#   B            1             20\n",
    "#   C            1             30\n",
    "#   D            2             70\n",
    "#   E            3             95\n",
    "\n",
    "# it should become\n",
    "# INCOME GROUP    BACHELOR ... (other columns, too)\n",
    "#   1                25\n",
    "#   2                60\n",
    "#   3                95\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# END OF YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Wrapping Up</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.7.1 [1 pt]: Conclusions</b>\n",
    "What are your conclusions/finding from this alternative view of the data? (2-4 sentences).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#F6FEFA;padding:15px'>\n",
    "\n",
    "**your answer here**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b>Exercise 4.7.2 [1 pt]: Possible Weaknesses</b>\n",
    "What are some weaknesses from this view of the data? (2-4 sentences).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#F6FEFA;padding:15px'>\n",
    "\n",
    "**your answer here**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Forward\n",
    "\n",
    "In this homework assignment, we've focused on gathering, parsing, and exploring data. However, what if we wanted to *predict* some behavior of the data. For example, imagine one is curious how a particular county will respond to COVID. Or, imagine we looked at counties' COVID data on a weekly basis, one could be interested in predicting the upcoming week's behavior.\n",
    "\n",
    "Alternatively, one could be interested in *inference*, whereby we are more concerned with trying to understand __why__ and __how__ a system behaves the way it does. We might wish to understand which factors most correlate and cause a certain event to happen. This could give us insights into where certain inequalities persist.\n",
    "\n",
    "For both *prediction* and *inference*, our computational method of solving such a task is referred to as a model. For the remainder of CS109, we will spend significant focus on various models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "As a reminder, this is just **one** of the homework assignments in this course, the point of which is to assess your learning and to provide both you and us with an indication as to how aligned your knowledge and skills are with our learning objectives. To this end, we encourage you to reflect on your progress, strengths, and weaknesses and to make changes, if necessary, to accomplish your goals. Likewise, please reach out to the TFs and teaching staff if you need help. We want everyone to feel comfortable in being honest about these elements, with both herself/himself and us. For these purposes, we will ask you several times throughout the semester to complete an anonymous poll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
